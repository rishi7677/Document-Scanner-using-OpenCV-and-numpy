{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a document scanner using OpenCV and NumPy\n",
    "\n",
    "First go and download: \n",
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Read the photograph or image\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "# parameter for image to scan/process\n",
    "args_image = \"bill.png\"\n",
    "# read the image\n",
    "image = cv2.imread(args_image)\n",
    "orig = image.copy()\n",
    "# show the original image\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0) # press 0 to close all cv2 windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Identify the edges\n",
    "\n",
    "# convert image to gray scale. This will remove any color noise\n",
    "grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# blur the image to remove high frequency noise \n",
    "# it helps in finding/detecting contour in gray image\n",
    "grayImageBlur = cv2.blur(grayImage,(3,3))\n",
    "# then we performed canny edge detection\n",
    "edgedImage = cv2.Canny(grayImageBlur, 100, 300, 3)\n",
    "# show the gray and edge-detected image\n",
    "cv2.imshow(\"gray\", grayImage)\n",
    "cv2.imshow(\"grayBlur\", grayImageBlur)\n",
    "cv2.imshow(\"Edge Detected Image\", edgedImage)\n",
    "cv2.waitKey(0) # press 0 to close all cv2 windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Detect document edges in the image:\n",
    "\n",
    "# find the contours in the edged image, sort area wise \n",
    "# keeping only the largest ones \n",
    "allContours = cv2.findContours(edgedImage.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "allContours = imutils.grab_contours(allContours)\n",
    "# descending sort contours area and keep top 1\n",
    "allContours = sorted(allContours, key=cv2.contourArea, reverse=True)[:1]\n",
    "# approximate the contour\n",
    "perimeter = cv2.arcLength(allContours[0], True) \n",
    "ROIdimensions = cv2.approxPolyDP(allContours[0], 0.02*perimeter, True)\n",
    "# show the contour on image\n",
    "cv2.drawContours(image, [ROIdimensions], -1, (0,255,0), 2)\n",
    "cv2.imshow(\"Contour Outline\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Identify and extract document boundary/edges:\n",
    "\n",
    "# reshape coordinates array\n",
    "ROIdimensions = ROIdimensions.reshape(4,2)\n",
    "# list to hold ROI coordinates\n",
    "rect = np.zeros((4,2), dtype=\"float32\")\n",
    "# top left corner will have the smallest sum, \n",
    "# bottom right corner will have the largest sum\n",
    "s = np.sum(ROIdimensions, axis=1)\n",
    "rect[0] = ROIdimensions[np.argmin(s)]\n",
    "rect[2] = ROIdimensions[np.argmax(s)]\n",
    "# top-right will have smallest difference\n",
    "# botton left will have largest difference\n",
    "diff = np.diff(ROIdimensions, axis=1)\n",
    "rect[1] = ROIdimensions[np.argmin(diff)]\n",
    "rect[3] = ROIdimensions[np.argmax(diff)]\n",
    "# top-left, top-right, bottom-right, bottom-left\n",
    "(tl, tr, br, bl) = rect\n",
    "# compute width of ROI\n",
    "widthA = np.sqrt((tl[0] - tr[0])**2 + (tl[1] - tr[1])**2 )\n",
    "widthB = np.sqrt((bl[0] - br[0])**2 + (bl[1] - br[1])**2 )\n",
    "maxWidth = max(int(widthA), int(widthB))\n",
    "# compute height of ROI\n",
    "heightA = np.sqrt((tl[0] - bl[0])**2 + (tl[1] - bl[1])**2 )\n",
    "heightB = np.sqrt((tr[0] - br[0])**2 + (tr[1] - br[1])**2 )\n",
    "maxHeight = max(int(heightA), int(heightB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Apply perspective transform:\n",
    "\n",
    "# Set of destinations points for \"birds eye view\"\n",
    "# dimension of the new image\n",
    "dst = np.array([\n",
    "    [0,0],\n",
    "    [maxWidth-1, 0],\n",
    "    [maxWidth-1, maxHeight-1],\n",
    "    [0, maxHeight-1]], dtype=\"float32\")\n",
    "# compute the perspective transform matrix and then apply it\n",
    "transformMatrix = cv2.getPerspectiveTransform(rect, dst)\n",
    "# transform ROI\n",
    "scan = cv2.warpPerspective(orig, transformMatrix, (maxWidth, maxHeight))\n",
    "# lets see the wraped document\n",
    "cv2.imshow(\"Scaned\",scan)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sickit_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-244ba5578803>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# ------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# convert to black/white with high contrast for documents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msickit_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mthreshold_local\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# increase contrast incase its document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreshold_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscanGray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gaussian\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sickit_image'"
     ]
    }
   ],
   "source": [
    "# Step 6 \n",
    "\n",
    "# convert to gray\n",
    "scanGray = cv2.cvtColor(scan, cv2.COLOR_BGR2GRAY)\n",
    "# display final gray image\n",
    "cv2.imshow(\"scanGray\", scanGray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# ------------------------------\n",
    "# convert to black/white with high contrast for documents\n",
    "from sickit_image.filters import threshold_local\n",
    "# increase contrast incase its document\n",
    "T = threshold_local(scanGray, 9, offset=8, method=\"gaussian\")\n",
    "scanBW = (scanGray > T).astype(\"uint8\") * 255\n",
    "# display final high-contrast image\n",
    "cv2.imshow(\"scanBW\", scanBW)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
